{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'misc.forsale', 'soc.religion.christian']\n",
    "\n",
    "train_dataset = fetch_20newsgroups(subset = 'train', categories = categories, shuffle=True,random_state=None)\n",
    "test_dataset = fetch_20newsgroups(subset = 'test', categories = categories, shuffle=True,random_state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## stop words\n",
    "import nltk\n",
    "from sklearn.feature_extraction import text\n",
    "stop_words_skt = text.ENGLISH_STOP_WORDS\n",
    "# nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words_en = stopwords.words('english')\n",
    "from string import punctuation\n",
    "combined_stopwords = set.union(set(stop_words_en),set(punctuation),set(stop_words_skt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lemmatizer\n",
    "from nltk import pos_tag\n",
    "# nltk.download('punkt')#, if you need \"tokenizers/punkt/english.pickle\", choose it\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "\n",
    "def penn2morphy(penntag):\n",
    "    \"\"\" Converts Penn Treebank tags to WordNet. \"\"\"\n",
    "    morphy_tag = {'NN':'n', 'JJ':'a',\n",
    "                  'VB':'v', 'RB':'r'}\n",
    "    try:\n",
    "        return morphy_tag[penntag[:2]]\n",
    "    except:\n",
    "        return 'n'\n",
    "\n",
    "def lemmatize_sent_demo(text):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(nltk.word_tokenize(text))]\n",
    "def lemmatize_sent(list_word):\n",
    "    # Text input is string, returns array of lowercased strings(words).\n",
    "    return [wnl.lemmatize(word.lower(), pos=penn2morphy(tag)) \n",
    "            for word, tag in pos_tag(list_word)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite analyzer with callable function:\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "def stem_rmv_punc(doc):\n",
    "    return (word for word in lemmatize_sent(analyzer(doc)) if word not in combined_stopwords and not is_number(word))\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "pipe_min_df_3_NMF_NB = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3, analyzer=stem_rmv_punc, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', NMF(n_components=50, init='random', random_state=0)),\n",
    "    ('clf', GaussianNB()),\n",
    "])\n",
    "\n",
    "pipe_min_df_3_LSI_NB = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3, analyzer=stem_rmv_punc, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(n_components=50, random_state=0)),\n",
    "    ('clf', GaussianNB()),\n",
    "])\n",
    "\n",
    "# SVM one vs one\n",
    "pipeline_min_df_3_NMF_SVM_ovo = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3, analyzer=stem_rmv_punc, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', NMF(n_components=50, init='random', random_state=0)),\n",
    "    ('clf', SVC(C=1,gamma=10,probability=True, decision_function_shape='ovo'))])\n",
    "\n",
    "pipeline_min_df_3_LSI_SVM_ovo = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3, analyzer=stem_rmv_punc, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(n_components=50, random_state=0)),\n",
    "    ('clf', SVC(C=1,gamma=10,probability=True, decision_function_shape='ovo'))])\n",
    "\n",
    "# SVM one vs rest\n",
    "pipeline_min_df_3_NMF_SVM_ovr = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3, analyzer=stem_rmv_punc, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', NMF(n_components=50, init='random', random_state=0)),\n",
    "    ('clf', LinearSVC())])\n",
    "\n",
    "pipeline_min_df_3_LSI_SVM_ovr = Pipeline([\n",
    "    ('vect', CountVectorizer(min_df=3, analyzer=stem_rmv_punc, stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('reduce_dim', TruncatedSVD(n_components=50, random_state=0)),\n",
    "    ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    roc_auc = auc(fpr,tpr)\n",
    "\n",
    "    ax.plot(fpr, tpr, lw=2, label= 'area under curve = %0.4f' % roc_auc)\n",
    "\n",
    "    ax.grid(color='0.7', linestyle='--', linewidth=1)\n",
    "\n",
    "    ax.set_xlim([-0.1, 1.1])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate',fontsize=15)\n",
    "    ax.set_ylabel('True Positive Rate',fontsize=15)\n",
    "\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    for label in ax.get_xticklabels()+ax.get_yticklabels():\n",
    "        label.set_fontsize(15)\n",
    "        \n",
    "def fit_predict_and_plot_roc(pipe, train_data, train_label, test_data, test_label):\n",
    "    pipe.fit(train_data, train_label)\n",
    "    \n",
    "    predicted_labels = pipe.predict(test_data)\n",
    "    print('confusion_matrix =', '\\n', confusion_matrix(test_label, predicted_labels))\n",
    "    print('accuracy score =', accuracy_score(test_label, predicted_labels))\n",
    "    print('recall score =', recall_score(test_label, predicted_labels,average='macro'))\n",
    "    print('precision score =', precision_score(test_label, predicted_labels, average='macro'))\n",
    "    print('F1 score =', f1_score(test_label, predicted_labels, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix = \n",
      " [[303  64  25   0]\n",
      " [ 76 281  27   1]\n",
      " [ 47  22 320   1]\n",
      " [  9   2   8 379]]\n",
      "accuracy score = 0.819808306709\n",
      "recall score = 0.818900860147\n",
      "precision score = 0.82373131466\n",
      "F1 score = 0.820584582024\n"
     ]
    }
   ],
   "source": [
    "# SVM one vs one\n",
    "fit_predict_and_plot_roc(pipeline_min_df_3_NMF_SVM_ovo, train_dataset.data, train_dataset.target, test_dataset.data, test_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix = \n",
      " [[326  39  26   1]\n",
      " [ 44 314  27   0]\n",
      " [ 22  18 348   2]\n",
      " [  6   1   1 390]]\n",
      "accuracy score = 0.880511182109\n",
      "recall score = 0.87985606461\n",
      "precision score = 0.880304888224\n",
      "F1 score = 0.87994709393\n"
     ]
    }
   ],
   "source": [
    "# SVM one vs one\n",
    "fit_predict_and_plot_roc(pipeline_min_df_3_LSI_SVM_ovo, train_dataset.data, train_dataset.target, test_dataset.data, test_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix = \n",
      " [[282  65  43   2]\n",
      " [ 68 278  35   4]\n",
      " [ 41  19 327   3]\n",
      " [  0   1   9 388]]\n",
      "accuracy score = 0.814696485623\n",
      "recall score = 0.813700396875\n",
      "precision score = 0.813563222286\n",
      "F1 score = 0.813288871546\n"
     ]
    }
   ],
   "source": [
    "# SVM one vs rest\n",
    "fit_predict_and_plot_roc(pipeline_min_df_3_NMF_SVM_ovr, train_dataset.data, train_dataset.target, test_dataset.data, test_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix = \n",
      " [[314  53  25   0]\n",
      " [ 42 316  24   3]\n",
      " [ 20  20 348   2]\n",
      " [  4   1   1 392]]\n",
      "accuracy score = 0.875399361022\n",
      "recall score = 0.874757986091\n",
      "precision score = 0.874587400147\n",
      "F1 score = 0.874591906634\n"
     ]
    }
   ],
   "source": [
    "# SVM one vs rest\n",
    "fit_predict_and_plot_roc(pipeline_min_df_3_LSI_SVM_ovr, train_dataset.data, train_dataset.target, test_dataset.data, test_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix = \n",
      " [[287  50  46   9]\n",
      " [121 208  51   5]\n",
      " [ 52  45 284   9]\n",
      " [  2   1   3 392]]\n",
      "accuracy score = 0.748242811502\n",
      "recall score = 0.746383087181\n",
      "precision score = 0.747396073529\n",
      "F1 score = 0.743521126236\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "fit_predict_and_plot_roc(pipe_min_df_3_NMF_NB, train_dataset.data, train_dataset.target, test_dataset.data, test_dataset.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion_matrix = \n",
      " [[228  34 127   3]\n",
      " [ 95 158 130   2]\n",
      " [ 48  39 299   4]\n",
      " [  0   0  17 381]]\n",
      "accuracy score = 0.681150159744\n",
      "recall score = 0.67899384057\n",
      "precision score = 0.699319006424\n",
      "F1 score = 0.674652274163\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "fit_predict_and_plot_roc(pipe_min_df_3_LSI_NB, train_dataset.data, train_dataset.target, test_dataset.data, test_dataset.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
